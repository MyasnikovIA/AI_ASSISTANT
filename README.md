# Локальный AI Ассистент с RAG на Java

Простой локальный AI ассистент, использующий OLLAMA и векторную базу знаний в оперативной памяти для RAG (Retrieval-Augmented Generation).

## Особенности

- **Полностью локальный**: работает без интернета
- **Векторная БД в памяти**: использует до 70 ГБ оперативной памяти для быстрого поиска
- **RAG (Retrieval-Augmented Generation)**: объединяет поиск в базе знаний с генерацией ответов
- **Поддержка OLLAMA**: работает с любыми локальными LLM моделями через OLLAMA
- **Простое добавление знаний**: интуитивный интерфейс для пополнения базы знаний
- **Поиск по схожести**: поиск информации с использованием косинусной схожести

## Требования

1. **Java 11 или выше**
2. **OLLAMA** установленный и запущенный
3. **Минимум 8 ГБ ОЗУ** (рекомендуется 16+ ГБ для больших баз знаний)

## Установка и запуск

### 1. Установите OLLAMA
```bash
# Скачайте и установите OLLAMA с официального сайта
# https://ollama.com/